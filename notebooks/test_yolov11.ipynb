{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "a2-xJIdeTF1l",
        "bCVyrriCBxBh",
        "R9nK8K3vfSYq"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Activate GPU usage before running:\n",
        "\n",
        "**Runtime -> Change Runtime Type -> Choose GPU**"
      ],
      "metadata": {
        "id": "1q4csvmVIlSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notebook config"
      ],
      "metadata": {
        "id": "a2-xJIdeTF1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #**SETUP FOR TEST NOTEBOOK**\n",
        "#@markdown ---\n",
        "\n",
        "# Cell 0: ENVIRONMENT DETECTION & CONFIGURATION\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Detect if running in Colab\n",
        "RUNNING_IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if RUNNING_IN_COLAB:\n",
        "    BASE_DIR = '/content'\n",
        "    # Clone the RatTrack repo if missing\n",
        "    REPO_URL = 'https://github.com/leomaestri/RatTrack.git'\n",
        "    REPO_DIR = os.path.join(BASE_DIR, 'RatTrack')\n",
        "    if not os.path.exists(REPO_DIR):\n",
        "        subprocess.run(['git', 'clone', REPO_URL, REPO_DIR], check=True)\n",
        "\n",
        "    # Paths to model and test video\n",
        "    MODEL_PATH = os.path.join(REPO_DIR, 'data', 'model.pt')\n",
        "    VIDEO_PATH = os.path.join(REPO_DIR, 'data', 'test_video.MP4')\n",
        "\n",
        "    !cp {MODEL_PATH} \"/content/model.pt\"\n",
        "    MODEL_PATH = \"/content/model.pt\"\n",
        "    !cp {VIDEO_PATH} \"/content/test_video.MP4\"\n",
        "    VIDEO_PATH = \"/content/test_video.MP4\"\n",
        "else:\n",
        "    #@markdown **Ignore if using Colab**\n",
        "    #@markdown Enter the path where your local RatTrack repo lives (e.g. ~/projects/RatTrack)\n",
        "    local_repo_path = \"\"  #@param {type:\"string\"}\n",
        "    REPO_DIR = os.path.expanduser(local_repo_path or '~/proyecto/RatTrack')\n",
        "\n",
        "    # Paths to model and test video\n",
        "    MODEL_PATH = os.path.join(REPO_DIR, 'data', 'model.pt')\n",
        "    VIDEO_PATH = os.path.join(REPO_DIR, 'data', 'test_video.MP4')\n",
        "\n",
        "!pip install -r {REPO_DIR}/requirements.txt\n",
        "\n",
        "print(f\"Model path: {MODEL_PATH}\")\n",
        "print(f\"Test video: {VIDEO_PATH}\")"
      ],
      "metadata": {
        "id": "d5qffQk7jLEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "id": "-alTgmy3zR5H",
        "outputId": "09c5c757-55d6-4595-f98f-f42ff3aecef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.163 ðŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 42.6/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "import yaml\n",
        "import random\n",
        "import shutil\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "jjjkQPm1MuuA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load and preprocess video\n",
        "\n"
      ],
      "metadata": {
        "id": "bCVyrriCBxBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Load video on colab and reference with path. Default **test_video.MP4** from repository\n",
        "VIDEO_PATH = \"/content/test_video.MP4\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "igBcOxf2ELm8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reduce processing time and operations we will:\n",
        "* Reduce FPS (Frames Per Second) to 10\n",
        "* Crop the image only to the relevant part of the video\n",
        "* Start from the relevant moment of the video"
      ],
      "metadata": {
        "id": "OyLAjrLldM3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from drive if needed, otherwise just load on notebook Files directly\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#!cp -r \"/content/drive/MyDrive/...\" \"/content/\""
      ],
      "metadata": {
        "id": "wPc1zKqNByPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open video and extract metadata\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"No pude abrir {VIDEO_PATH}\")\n",
        "\n",
        "fps         = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "width       = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height      = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Read a frame to check channels\n",
        "ret, frame = cap.read()\n",
        "if not ret:\n",
        "    raise RuntimeError(\"No pude leer el primer frame\")\n",
        "channels = frame.shape[2]  # usually 3 (BGR)\n",
        "\n",
        "print(f\"VÃ­deo: {VIDEO_PATH}\")\n",
        "print(f\"  â€¢ ResoluciÃ³n: {width}Ã—{height}\")\n",
        "print(f\"  â€¢ FPS: {fps}\")\n",
        "print(f\"  â€¢ Total frames: {frame_count}\")\n",
        "print(f\"  â€¢ Canales por frame: {channels}\")\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqOdsCY60_IN",
        "outputId": "a8f55ebf-6ea0-4513-8b77-83a21ee81fee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VÃ­deo: /content/test_video.MP4\n",
            "  â€¢ ResoluciÃ³n: 1280Ã—720\n",
            "  â€¢ FPS: 29.97002997002997\n",
            "  â€¢ Total frames: 10260\n",
            "  â€¢ Canales por frame: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce FPS to 10\n",
        "!ffmpeg -i {VIDEO_PATH} -vf fps=10 ./video_to_10fps.mp4\n",
        "\n",
        "print(f\"Change FPS from {fps} to 10\")"
      ],
      "metadata": {
        "id": "k-fWdE0-FOqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VIDEO_PATH = './video_to_10fps.mp4'\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "# 1) Check that the video opened successfully\n",
        "if not cap.isOpened():\n",
        "    cap.release()\n",
        "    raise IOError(f\"Could not open the video: {VIDEO_PATH}\")\n",
        "\n",
        "# 2) Get the total number of frames and verify it's > 0\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "if total_frames <= 0:\n",
        "    cap.release()\n",
        "    raise ValueError(f\"No frames found in the video (total_frames={total_frames})\")\n",
        "\n",
        "# 3) Select a random index between 0 and total_frames-1\n",
        "rand_idx = random.randint(0, total_frames - 1)\n",
        "\n",
        "# 4) Seek to that frame and read it\n",
        "cap.set(cv2.CAP_PROP_POS_FRAMES, rand_idx)\n",
        "ret, frame = cap.read()\n",
        "cap.release()\n",
        "\n",
        "if not ret or frame is None:\n",
        "    raise RuntimeError(f\"Error reading frame #{rand_idx}\")\n",
        "\n",
        "# 5) Convert BGRâ†’RGB and display it\n",
        "frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "h, w, _ = frame_rgb.shape\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(frame_rgb)\n",
        "plt.title(f'Random frame #{rand_idx} ({w}Ã—{h})')\n",
        "\n",
        "# Adjust ticks every 50 pixels to avoid clutter\n",
        "plt.xticks(range(0, w+1, 50))\n",
        "plt.yticks(range(0, h+1, 50))\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"Y\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"From the random frame of the image, save the upper left and bottom right corners to crop the video with a square\")\n",
        "print(f\"You will use the corners on the following cells with the format (x, y)\")"
      ],
      "metadata": {
        "id": "6jfDlDiYEdl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Choose X and Y coordinates from Top Left corner Bottom Right corner for a rectangle to crop the video\n",
        "left_top_corner_x = 300 #@param {type:\"number\"}\n",
        "left_top_corner_y = 100 #@param {type:\"number\"}\n",
        "right_bottom_corner_x = 800 #@param {type:\"number\"}\n",
        "right_bottom_corner_y = 600 #@param {type:\"number\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y8lZdaTEGgvt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total frames\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    raise RuntimeError(f\"Cannot open video: {VIDEO_PATH}\")\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "cap.release()\n",
        "\n",
        "def preview_crop(x1, y1, x2, y2):\n",
        "    \"\"\"Display a random frame cropped according to the given coordinates.\"\"\"\n",
        "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "    idx = random.randint(0, total_frames - 1)\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "    ret, frame = cap.read()\n",
        "    cap.release()\n",
        "    if not ret:\n",
        "        print(f\"Could not read frame #{idx}\")\n",
        "        return\n",
        "    crop = frame[y1:y2, x1:x2]\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.imshow(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Frame #{idx} cropped: ({x1},{y1}) â†’ ({x2},{y2})')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "print(\"Selecting a random frame to check if crop is ok\\n\")\n",
        "preview_crop(left_top_corner_x, left_top_corner_y, right_bottom_corner_x, right_bottom_corner_y)\n",
        "print(\"\\nIf crop is ok continue to crop the whole video. Otherwise change the coordinates and rerun this cell\")"
      ],
      "metadata": {
        "id": "JWGK1Lu8FqO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute full video crop with FFmpeg\n",
        "width, height = right_bottom_corner_x - left_top_corner_x, right_bottom_corner_y - left_top_corner_y\n",
        "output_path = './video_to_10fps_cropped.mp4'\n",
        "cmd = (\n",
        "    f'ffmpeg -i \"{VIDEO_PATH}\" '\n",
        "    f'-filter:v \"crop={width}:{height}:{left_top_corner_x}:{left_top_corner_y}\" '\n",
        "    f'-c:a copy \"{output_path}\"'\n",
        ")\n",
        "print(\"Running crop on the entire video...\")\n",
        "os.system(cmd)\n",
        "print(f\"Cropped video saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "2V5UzgIdH5rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference on preprocessed video"
      ],
      "metadata": {
        "id": "R9nK8K3vfSYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Adjust these paths --\n",
        "VIDEO_IN     = './video_to_10fps_cropped.mp4'\n",
        "OUT_DIR      = './inference'\n",
        "OUT_VIDEO    = os.path.join(OUT_DIR, 'annotated.mp4')\n",
        "N_FRAMES_REF = 3     # how many random frames to save\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(f'{OUT_DIR}/frames', exist_ok=True)\n",
        "os.makedirs(f'{OUT_DIR}/labels', exist_ok=True)\n",
        "\n",
        "# 1) get total frames, FPS, and dimensions\n",
        "cap = cv2.VideoCapture(VIDEO_IN)\n",
        "total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "fps   = cap.get(cv2.CAP_PROP_FPS)\n",
        "w     = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "h     = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "cap.release()\n",
        "\n",
        "refs = set(random.sample(range(total), N_FRAMES_REF))\n",
        "print(f\"Reference frames (no overlay): {sorted(refs)}  FPS={fps:.2f}, total={total}, size={w}Ã—{h}\")\n",
        "\n",
        "# 2) prepare writer for annotated video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "writer = cv2.VideoWriter(OUT_VIDEO, fourcc, fps, (w, h))\n",
        "\n",
        "# 3) load OBB model\n",
        "model = YOLO(MODEL_PATH)\n",
        "\n",
        "# 4) streaming OBB inference\n",
        "for i, r in enumerate(tqdm(model.predict(\n",
        "        source=VIDEO_IN, stream=True, conf=0.25, imgsz=640, task='obb'\n",
        "    ))):\n",
        "    # extract polygons and xywhr parameters\n",
        "    if r.obb is not None and len(r.obb.xyxyxyxy):\n",
        "        polys  = r.obb.xyxyxyxy.cpu().numpy().reshape(-1,8).astype(int)  # NÃ—8\n",
        "        clses  = r.obb.cls  .cpu().numpy().astype(int)                    # N\n",
        "        confs  = r.obb.conf .cpu().numpy()                               # N\n",
        "    else:\n",
        "        polys = np.zeros((0,8), int)\n",
        "        clses = np.zeros((0,),   int)\n",
        "        confs = np.zeros((0,), float)\n",
        "\n",
        "    # dump .txt with: cls x1 y1 x2 y2 x3 y3 x4 y4 conf\n",
        "    lbl_path = f'{OUT_DIR}/labels/frame_{i:06d}.txt'\n",
        "    with open(lbl_path, 'w') as f:\n",
        "        for poly, cls, conf in zip(polys, clses, confs):\n",
        "            coords = ' '.join(map(str, poly.tolist()))\n",
        "            f.write(f\"{cls} {coords} {conf:.3f}\\n\")\n",
        "\n",
        "    # get the original BGR frame\n",
        "    orig_frame = r.orig_img.copy()\n",
        "\n",
        "    # save reference frames *without overlay*\n",
        "    if i in refs:\n",
        "        cv2.imwrite(f'{OUT_DIR}/frames/frame_{i:06d}.png', orig_frame)\n",
        "\n",
        "    # draw only the OBB polygon on all other frames\n",
        "    frame = orig_frame.copy()\n",
        "    for poly in polys:\n",
        "        pts = poly.reshape(4,2)\n",
        "        cv2.polylines(frame, [pts], isClosed=True, color=(0,255,0), thickness=2)\n",
        "\n",
        "    # write the annotated frame to the video\n",
        "    writer.write(frame)\n",
        "\n",
        "# close the writer\n",
        "writer.release()\n",
        "\n",
        "# 5) compress everything into a ZIP\n",
        "zip_path = shutil.make_archive(OUT_DIR, 'zip', OUT_DIR)\n",
        "\n",
        "print(\"-----OBB inference complete-----\")\n",
        "print(f\" Labels in {OUT_DIR}/labels\")\n",
        "print(f\"Reference frames (no overlay) in {OUT_DIR}/frames\")\n",
        "print(f\"Annotated video at {OUT_VIDEO}\")\n",
        "print(f\"Everything archived to {zip_path}\")"
      ],
      "metadata": {
        "id": "hhS0HVUVs1n8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}